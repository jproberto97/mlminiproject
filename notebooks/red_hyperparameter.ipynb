{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Drugs Dataset and Assign Predictor and Target Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.231405</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.089041</td>\n",
       "      <td>0.120401</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.038869</td>\n",
       "      <td>0.611601</td>\n",
       "      <td>0.267717</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.160714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.209091</td>\n",
       "      <td>0.512397</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>0.070234</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.035336</td>\n",
       "      <td>0.367841</td>\n",
       "      <td>0.559055</td>\n",
       "      <td>0.149068</td>\n",
       "      <td>0.553571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.718182</td>\n",
       "      <td>0.396694</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.147157</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.028269</td>\n",
       "      <td>0.802496</td>\n",
       "      <td>0.401575</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.209091</td>\n",
       "      <td>0.347107</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.143836</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.074205</td>\n",
       "      <td>0.633627</td>\n",
       "      <td>0.748031</td>\n",
       "      <td>0.322981</td>\n",
       "      <td>0.178571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.381818</td>\n",
       "      <td>0.264463</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.130137</td>\n",
       "      <td>0.118729</td>\n",
       "      <td>0.253731</td>\n",
       "      <td>0.371025</td>\n",
       "      <td>0.596916</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.196429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0       0.563636          0.231405         0.41        0.089041   0.120401   \n",
       "1       0.209091          0.512397         0.03        0.095890   0.070234   \n",
       "2       0.718182          0.396694         0.49        0.232877   0.147157   \n",
       "3       0.209091          0.347107         0.04        0.143836   0.108696   \n",
       "4       0.381818          0.264463         0.49        0.130137   0.118729   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide   density        pH  sulphates  \\\n",
       "0             0.089552              0.038869  0.611601  0.267717   0.173913   \n",
       "1             0.089552              0.035336  0.367841  0.559055   0.149068   \n",
       "2             0.059701              0.028269  0.802496  0.401575   0.217391   \n",
       "3             0.089552              0.074205  0.633627  0.748031   0.322981   \n",
       "4             0.253731              0.371025  0.596916  0.440945   0.130435   \n",
       "\n",
       "    alcohol  \n",
       "0  0.160714  \n",
       "1  0.553571  \n",
       "2  0.625000  \n",
       "3  0.178571  \n",
       "4  0.196429  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.read_csv(\"x_train_red.csv\")\n",
    "x_normalized = (x - x.min()) / (x.max() - x.min())\n",
    "x_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   3  4  5  6  7  8\n",
       "0  0  0  0  1  0  0\n",
       "1  0  0  0  1  0  0\n",
       "2  0  0  0  1  0  0\n",
       "3  0  0  0  1  0  0\n",
       "4  0  0  1  0  0  0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Since y is already one-hot encoded, no need to get dummies\n",
    "y = pd.read_csv(\"y_train_red.csv\")\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len Input: 11\n",
      "Len Output: 6\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_normalized, y, test_size=0.3)\n",
    "\n",
    "len_input = len(x_train.columns)\n",
    "len_output = len(y_train.columns)\n",
    "\n",
    "print(\"Len Input: {}\".format(len_input))\n",
    "print(\"Len Output: {}\".format(len_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(x, y, x_validation, y_validation, params):\n",
    "    model = MLPClassifier(\n",
    "        random_state=1, \n",
    "        max_iter=1000,\n",
    "        alpha=params['alpha'],\n",
    "        learning_rate_init=params['learning_rate']\n",
    "    )\n",
    "\n",
    "    model.fit(x, y)\n",
    "\n",
    "    predictions = model.predict(x_validation)\n",
    "\n",
    "    return mean_squared_error(predictions, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parameters = [\n",
    "    { 'alpha': 0.002, 'learning_rate': 0.01 },\n",
    "    { 'alpha': 0.003, 'learning_rate': 0.009 },\n",
    "    { 'alpha': 0.004, 'learning_rate': 0.008 },\n",
    "    { 'alpha': 0.005, 'learning_rate': 0.007 },\n",
    "    { 'alpha': 0.006, 'learning_rate': 0.006 },\n",
    "    { 'alpha': 0.007, 'learning_rate': 0.005 },\n",
    "    { 'alpha': 0.008, 'learning_rate': 0.004 },\n",
    "    { 'alpha': 0.009, 'learning_rate': 0.003 },\n",
    "    { 'alpha': 0.002, 'learning_rate': 0.003 },\n",
    "    { 'alpha': 0.003, 'learning_rate': 0.004 },\n",
    "    { 'alpha': 0.004, 'learning_rate': 0.005 },\n",
    "    { 'alpha': 0.005, 'learning_rate': 0.006 },\n",
    "    { 'alpha': 0.006, 'learning_rate': 0.007 },\n",
    "    { 'alpha': 0.007, 'learning_rate': 0.008 },\n",
    "    { 'alpha': 0.008, 'learning_rate': 0.009 },\n",
    "    { 'alpha': 0.009, 'learning_rate': 0.01 }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.12710765239948119\n",
      "Loss: 0.13813229571984434\n",
      "Loss: 0.13359273670557717\n",
      "Loss: 0.13035019455252916\n",
      "Loss: 0.13748378728923474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\APONCE\\Desktop\\group\\mlminiproject\\env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.14591439688715954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\APONCE\\Desktop\\group\\mlminiproject\\env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1420233463035019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\APONCE\\Desktop\\group\\mlminiproject\\env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.13748378728923474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\APONCE\\Desktop\\group\\mlminiproject\\env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.13424124513618677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\APONCE\\Desktop\\group\\mlminiproject\\env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.13424124513618677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\APONCE\\Desktop\\group\\mlminiproject\\env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.13813229571984434\n",
      "Loss: 0.12645914396887156\n",
      "Loss: 0.13035019455252916\n",
      "Loss: 0.13164721141374838\n",
      "Loss: 0.13553826199740596\n",
      "Loss: 0.1251621271076524\n",
      "Best Loss: 0.1251621271076524\n",
      "Best params: {'alpha': 0.009, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "best_params = None\n",
    "current_loss = 1000\n",
    "\n",
    "for params in grid_parameters:\n",
    "    loss = objective_function(x_train.values, y_train.values, x_test.values, y_test.values, params)\n",
    "    print(\"Loss: {}\".format(loss))\n",
    "\n",
    "    if loss < current_loss:\n",
    "        best_params = params\n",
    "        current_loss = loss\n",
    "\n",
    "print(\"Best Loss: {}\".format(current_loss))\n",
    "print(\"Best params: {}\".format(best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_samples = 10\n",
    "# best_params = None\n",
    "# current_loss = 1000\n",
    "\n",
    "# for i in range(num_samples):\n",
    "#     params = {\n",
    "#         'alpha': random.randrange(0, 100) * 0.0001,\n",
    "#         'learning_rate': random.randrange(0, 100) * 0.0001\n",
    "#     }\n",
    "\n",
    "#     loss = objective_function(x_train.values, y_train.values, x_test.values, y_test.values, params)\n",
    "#     print(\"Loss: {}\".format(loss))\n",
    "\n",
    "#     if loss < current_loss:\n",
    "#         best_params = params\n",
    "#         current_loss = loss\n",
    "\n",
    "# print(\"Best Loss: {}\".format(current_loss))\n",
    "# print(\"Best params: {}\".format(best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Building my current belief\n",
    "# x_samples = []\n",
    "# y_samples = []\n",
    "\n",
    "# num_samples = 10\n",
    "# for i in range(num_samples):\n",
    "#     params = {\n",
    "#         'alpha': random.randrange(0, 100) * 0.0001,\n",
    "#         'learning_rate': random.randrange(0, 100) * 0.0001\n",
    "#     }\n",
    "\n",
    "#     loss = objective_function(x_train.values, y_train.values, x_test.values, y_test.values, params)\n",
    "#     print(\"Loss: {}\".format(loss))\n",
    "\n",
    "#     x1 = params['alpha']\n",
    "#     x2 = params['learning_rate']\n",
    "#     y = loss\n",
    "\n",
    "#     x_samples.append([x1, x2])\n",
    "#     y_samples.append([y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "# from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "# kernel = 1 * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2))\n",
    "# gaussian_process = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n",
    "# gaussian_process.fit(x_samples, y_samples)\n",
    "\n",
    "# mean, std = gaussian_process.predict(x_samples, return_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def f(params):\n",
    "#     model = MLPClassifier(\n",
    "#         random_state=1, \n",
    "#         max_iter=1000,\n",
    "#         alpha=params['alpha'],\n",
    "#         learning_rate_init=params['learning_rate']\n",
    "#     )\n",
    "    \n",
    "#     model.fit(x_train.values, y_train.values)\n",
    "\n",
    "#     predictions = model.predict(x_test.values)\n",
    "\n",
    "#     score = mean_squared_error(predictions, y_test.values)\n",
    "    \n",
    "#     return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from hyperopt import hp, fmin, tpe\n",
    "\n",
    "# params_list = {\n",
    "#     'alpha': hp.uniform('alpha', 0.001, 0.01),\n",
    "#     'learning_rate': hp.uniform('learning_rate', 0.0001, 0.001)\n",
    "# }\n",
    "\n",
    "# best_params = fmin(fn=f, space=params_list, max_evals=24, algo=tpe.suggest)\n",
    "\n",
    "# best_params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate a new model with `alpha` = 0.005 and `learning_rate` = 0.007"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d436f61485600065bbd78f0914ccd3502a94e56b5aeca30a275664867d5d71ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
